#!/usr/bin/env python3

import os
import sys
import re
import logging
import datetime
import time
import shutil
import subprocess
import json
from concurrent.futures import ThreadPoolExecutor
import typer
from pyfiglet import Figlet
from typing import Optional, List, Dict
from pathlib import Path

from rich.panel import Panel
from rich.align import Align
from rich.text import Text
from rich.table import Table
from rich.progress import Progress, BarColumn, SpinnerColumn, TimeElapsedColumn, MofNCompleteColumn, TaskID

# --- Add path to modules and import them ---
SHARE_DIR = "/usr/local/share/shadowmap/"
if SHARE_DIR not in sys.path:
    sys.path.insert(0, SHARE_DIR)

try:
    import config
    import utils
    import phase1_subdomain
    import phase2_port_scanning
    import phase3_dirsearch
    import phase4_webcrawling
except ImportError as e:
    print(f"BŁĄD: Nie można zaimportować modułów z {SHARE_DIR}. Uruchom install.py. Błąd: {e}", file=sys.stderr)
    sys.exit(1)

def display_banner():
    f = Figlet(font='slant')
    banner_text = f.renderText('ShadowMap')
    utils.console.print(Align.center(Text(banner_text, style="bold cyan")))
    utils.console.print(Align.center("--- Automated Reconnaissance Toolkit ---", style="bold yellow"))
    utils.console.print(Align.center("[dim white]Made by Xzar[/dim white]\n"))

def ask_scan_scope(all_results: List[str], critical_results: List[str], phase_name: str) -> Optional[List[str]]:
    summary_text = (
        f"Znaleziono [bold green]{len(all_results)}[/bold green] unikalnych wyników.\n"
        f"W tym [bold red]{len(critical_results)}[/bold red] oznaczono jako krytyczne."
    )
    panel = Panel(Text.from_markup(summary_text, justify="center"), border_style="cyan", title="[cyan]Podsumowanie[/cyan]")
    utils.console.print(Align.center(panel))

    question = f"Co chcesz przeskanować w {phase_name}?\n" \
               f"([bold]A[/bold])ll - wszystkie {len(all_results)} wyników\n" \
               f"([bold]C[/bold])ritical - tylko {len(critical_results)} krytycznych wyników"
    
    choice = utils.ask_user_decision(question, choices=["a", "c"], default="a")
    return all_results if choice.lower() == 'a' else critical_results

def display_main_menu():
    utils.console.clear()
    display_banner()
    main_panel = Panel.fit("[bold cyan]ShadowMap Main Menu[/bold cyan]")
    utils.console.print(Align.center(main_panel))
    utils.console.print(Align.center(f"\nObecny cel: [bold green]{config.ORIGINAL_TARGET}[/bold green]\n"))
    table = Table(show_header=False, show_edge=False, padding=(0, 2))
    table.add_column("Key", style="bold blue", justify="center", min_width=5)
    table.add_column("Description", style="white", justify="left")
    table.add_row("[1]", "Faza 1: Odkrywanie Subdomen")
    table.add_row("[2]", "Faza 2: Skanowanie Portów")
    table.add_row("[3]", "Faza 3: Wyszukiwanie Katalogów")
    table.add_row("[4]", "Faza 4: Web Crawling")
    table.add_row("[\fq]", "Wyjdź")
    utils.console.print(Align.center(table))
    return utils.get_single_char_input_with_prompt(Text.from_markup("\n[bold cyan]Wybierz fazę, od której chcesz zacząć[/bold cyan]", justify="center"))

def parse_target_input(target_input: str):
    config.ORIGINAL_TARGET = target_input
    clean_target = re.sub(r'^(http|https)://', '', target_input).strip('/')
    config.TARGET_IS_IP = bool(re.match(r"^\d{1,3}(\.\d{1,3}){3}$", clean_target))

    if not config.TARGET_IS_IP:
        hostname_match = re.search(r'([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', clean_target)
        if hostname_match:
            config.HOSTNAME_TARGET = hostname_match.group(1)
            parts = config.HOSTNAME_TARGET.split('.')
            if len(parts) > 2 and any(d in parts[-2] for d in ['co', 'com', 'org', 'net', 'gov', 'edu']) and len(parts) > 3:
                 config.CLEAN_DOMAIN_TARGET = '.'.join(parts[-3:])
            elif len(parts) > 1:
                 config.CLEAN_DOMAIN_TARGET = '.'.join(parts[-2:])
            else:
                 config.CLEAN_DOMAIN_TARGET = config.HOSTNAME_TARGET
        else:
            config.HOSTNAME_TARGET = clean_target
            config.CLEAN_DOMAIN_TARGET = clean_target
    else:
        config.HOSTNAME_TARGET = clean_target
        config.CLEAN_DOMAIN_TARGET = clean_target

    utils.console.print(Align.center(f"[bold green]Hostname celu: {config.HOSTNAME_TARGET} | Domena główna: {config.CLEAN_DOMAIN_TARGET}[/bold green]"))

def detect_waf_and_propose_safe_mode():
    initial_message = Text("Sprawdzam ochronę WAF...", justify="center")
    utils.console.print(Align.center(Panel(initial_message, title="[cyan]Detekcja WAF[/cyan]", expand=False, border_style="cyan")))
    
    try:
        command = ["wafw00f", "-T", "150", "--no-colors", config.ORIGINAL_TARGET]
        process = subprocess.run(command, capture_output=True, text=True, timeout=300, check=False)
        
        waf_name_match = re.search(r'is behind\s+([^\n(]+)', process.stdout)
        waf_name = waf_name_match.group(1).strip() if waf_name_match else None
        
        if waf_name:
            waf_detect_text = Text.from_markup(
                f"[bold red]Wykryto WAF:[/bold red] [bold blue]{waf_name}[/bold blue]",
                justify="center"
            )
            panel = Panel(
                waf_detect_text,
                title="[yellow]Wynik Detekcji[/yellow]",
                expand=False,
                border_style="yellow"
            )
            utils.console.print(Align.center(panel))

            if utils.ask_user_decision("Czy włączyć Tryb Bezpieczny?", ["y", "n"], "y") == 'y':
                config.SAFE_MODE = True
                if not config.USER_CUSTOMIZED_PROXY:
                    config.PROXY = "socks5://127.0.0.1:9050"
                safe_mode_panel = Panel(Text("Tryb Bezpieczny WŁĄCZONY.", justify="center", style="bold green"), expand=False)
                utils.console.print(Align.center(safe_mode_panel))
        else:
            no_waf_text = Text("Nie wykryto WAF.", justify="center")
            panel = Panel(
                no_waf_text, 
                title="[green]Wynik Detekcji[/green]", 
                expand=False, 
                border_style="green"
            )
            utils.console.print(Align.center(panel))

    except Exception as e:
        utils.log_and_echo(f"Błąd podczas uruchamiania wafw00f: {e}", "ERROR")

def open_html_report(report_path: str):
    if sys.platform == "win32": os.startfile(report_path)
    elif sys.platform == "darwin": subprocess.run(["open", report_path], check=False)
    else:
        try: subprocess.run(["xdg-open", report_path], check=False)
        except FileNotFoundError: utils.console.print("[yellow]xdg-open nie znaleziono. Otwórz raport ręcznie.[/yellow]")

def generate_html_report(p1_files: Dict, p2_results: Dict, p3_results: Dict, p3_verified_httpx: str, p4_raw_results: Dict):
    utils.console.print(Align.center("[bold blue]Generowanie raportu HTML...[/bold blue]"))
    
    def read_file_content(path: Optional[str]) -> str:
        if path and os.path.exists(path):
            try:
                with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
            except Exception:
                return "Błąd odczytu pliku"
        return "Brak danych"

    try:
        with open(config.HTML_TEMPLATE_PATH, 'r', encoding='utf-8') as f:
            template = f.read()
    except FileNotFoundError:
        utils.console.print(f"[bold red]BŁĄD: Nie znaleziono szablonu raportu: {config.HTML_TEMPLATE_PATH}[/bold red]")
        return
    
    # Process Phase 1 data
    httpx_raw = read_file_content(p1_files.get("Httpx"))
    subfinder_raw = read_file_content(p1_files.get("Subfinder"))
    assetfinder_raw = read_file_content(p1_files.get("Assetfinder"))
    findomain_raw = read_file_content(p1_files.get("Findomain"))
    puredns_raw = read_file_content(p1_files.get("Puredns"))

    all_subdomains_list = sorted(list(set(
        subfinder_raw.splitlines() + 
        assetfinder_raw.splitlines() +
        findomain_raw.splitlines() + 
        puredns_raw.splitlines()
    )))
    all_subdomains_raw = "\n".join(filter(None, all_subdomains_list))

    # Process Phase 2 data
    naabu_raw = read_file_content(p2_results.get("naabu_file"))
    nmap_panels = []
    for target, nmap_file in p2_results.get("nmap_files", {}).items():
        nmap_content = read_file_content(nmap_file)
        nmap_panels.append(f'<pre class="output"><strong>{target}</strong><br>{nmap_content}</pre>')
    
    # Process Phase 3 data
    dirsearch_all_raw = "\n".join(p3_results.get("all_dirsearch_results", []))
    dirsearch_specific_raw = "\n".join(p3_results.get("dirsearch", []))
    ffuf_raw = "\n".join(p3_results.get("ffuf", []))
    ferox_raw = "\n".join(p3_results.get("feroxbuster", []))
    gobuster_raw = "\n".join(p3_results.get("gobuster", []))
    
    # Process Phase 4 data
    p4_all_urls = "\n".join(p4_raw_results.get("all_urls", []))
    p4_params = "\n".join(p4_raw_results.get("parameters", []))
    p4_js = "\n".join(p4_raw_results.get("js_files", []))
    p4_api = "\n".join(p4_raw_results.get("api_endpoints", []))
    p4_interesting = "\n".join(p4_raw_results.get("interesting_paths", []))

    all_urls_combined = "\n".join(sorted(list(set(dirsearch_all_raw.splitlines() + p4_all_urls.splitlines()))))

    replacements = {
        "{{DOMAIN}}": config.HOSTNAME_TARGET,
        "{{COUNT_ALL_SUBDOMAINS}}": str(len(all_subdomains_raw.splitlines())),
        "{{COUNT_HTTPX}}": str(len(httpx_raw.splitlines())),
        "{{COUNT_OPEN_PORTS}}": str(len(naabu_raw.splitlines())),
        "{{COUNT_DIR_SEARCH}}": str(len(dirsearch_all_raw.splitlines())),
        "{{COUNT_ALL_URLS_P4}}": str(len(p4_all_urls.splitlines())),
        "{{COUNT_PARAMETERS}}": str(len(p4_params.splitlines())),
        "{{COUNT_JS_FILES}}": str(len(p4_js.splitlines())),
        "{{COUNT_API_ENDPOINTS}}": str(len(p4_api.splitlines())),
        "{{COUNT_INTERESTING_PATHS}}": str(len(p4_interesting.splitlines())),
        "{{HTTPX_OUTPUT_RAW_FOR_JS}}": json.dumps(httpx_raw),
        "{{SUBFINDER_OUTPUT}}": subfinder_raw.replace('\n', '<br>'),
        "{{ASSETFINDER_OUTPUT}}": assetfinder_raw.replace('\n', '<br>'),
        "{{FINDOMAIN_OUTPUT}}": findomain_raw.replace('\n', '<br>'),
        "{{PUREDNS_OUTPUT}}": puredns_raw.replace('\n', '<br>'),
        "{{NAABU_RESULTS}}": naabu_raw.replace('\n', '<br>'),
        "{{NMAP_RESULTS_PANEL}}": "\n".join(nmap_panels),
        "{{HTTPX_PHASE3_VERIFIED_OUTPUT}}": json.dumps(p3_verified_httpx),
        "{{DIR_SEARCH_ALL_OUTPUT}}": json.dumps(dirsearch_all_raw),
        "{{DIRSEARCH_SPECIFIC_OUTPUT}}": dirsearch_specific_raw.replace('\n', '<br>'),
        "{{FFUF_SPECIFIC_OUTPUT}}": ffuf_raw.replace('\n', '<br>'),
        "{{FEROXBUSTER_SPECIFIC_OUTPUT}}": ferox_raw.replace('\n', '<br>'),
        "{{GOBUSTER_SPECIFIC_OUTPUT}}": gobuster_raw.replace('\n', '<br>'),
        "{{PHASE4_ALL_URLS_OUTPUT}}": p4_all_urls.replace('\n', '<br>'),
        "{{PARAMETERS_OUTPUT}}": p4_params.replace('\n', '<br>'),
        "{{JS_FILES_OUTPUT}}": p4_js.replace('\n', '<br>'),
        "{{API_ENDPOINTS_OUTPUT}}": p4_api.replace('\n', '<br>'),
        "{{INTERESTING_PATHS_OUTPUT}}": p4_interesting.replace('\n', '<br>'),
        "{{ALL_SUBDOMAINS_OUTPUT}}": all_subdomains_raw.replace('\n', '<br>'),
        "{{ALL_URLS_COMBINED_OUTPUT}}": all_urls_combined.replace('\n', '<br>'),
        "{{COUNT_ALL_URLS_COMBINED}}": str(len(all_urls_combined.splitlines()))
    }

    for placeholder, value in replacements.items():
        template = template.replace(placeholder, value if value.strip() and "Brak danych" not in value else "Brak danych")

    report_path = os.path.join(config.REPORT_DIR, "report.html")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(template)
    
    utils.console.print(f"[bold green]✓ Raport HTML wygenerowany: {report_path}[/bold green]")

def cleanup_temp_files():
    utils.console.print(Align.center("Czyszczę pliki tymczasowe...", style="bold green"))
    for f_path in config.TEMP_FILES_TO_CLEAN:
        try:
            if os.path.exists(f_path): os.remove(f_path)
        except OSError as e:
            utils.log_and_echo(f"Nie można usunąć pliku '{f_path}': {e}", "WARN")

@typer.run
def main(
    target: str = typer.Argument(..., help="Domena lub adres IP do skanowania."),
    quiet: bool = typer.Option(False, "--quiet", "-q", help="Uruchamia skanowanie w trybie cichym (nieinteraktywnym)."),
    output_dir: Optional[Path] = typer.Option(None, "--output-dir", "-o", help="Katalog wyjściowy dla raportu."),
    assume_yes: bool = typer.Option(False, "--yes", "-y", help="Automatycznie akceptuje wszystkie interaktywne monity."),
    no_report: bool = typer.Option(False, "--no-report", help="Pomija generowanie raportu HTML."),
    log_file: Optional[Path] = typer.Option(None, "--log-file", "-l", help="Zapisuje logi do pliku."),
    proxy: Optional[str] = typer.Option(None, "--proxy", help="Adres URL proxy (np. http://127.0.0.1:8080)."),
    use_tor: bool = typer.Option(False, "--tor", help="Użyj Tor jako proxy dla Faz 3 i 4.")
):
    scan_initiated = False
    # Initialize results dictionaries
    p1_files, active_urls, all_subdomains = {}, [], []
    p2_results, p3_results, p4_results = {}, {}, {}
    p3_verified_httpx = ""
    
    try:
        config.QUIET_MODE = quiet or assume_yes
        if log_file:
            config.LOG_FILE = str(log_file)
            logging.basicConfig(filename=config.LOG_FILE, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        if output_dir: config.OUTPUT_BASE_DIR = str(output_dir)
        parse_target_input(target)
        if use_tor: config.PROXY = "socks5://127.0.0.1:9050"
        if proxy: config.PROXY = proxy

        if config.QUIET_MODE:
            config.selected_phase1_tools = [1,1,1,1] if not config.TARGET_IS_IP else [0,0,0,1]
            config.selected_phase2_tools = [1,1]
            config.selected_phase3_tools = [1,1,1,1]
            config.selected_phase4_tools = [1,1,1,1,1]
            start_phase = 1
        else:
            choice = display_main_menu()
            start_phase = int(choice) if choice.isdigit() else 0

        if not start_phase: return

        scan_initiated = True
        config.REPORT_DIR = os.path.join(config.OUTPUT_BASE_DIR, f"report_{config.HOSTNAME_TARGET}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}")
        os.makedirs(config.REPORT_DIR, exist_ok=True)
        utils.console.print(Align.center(f"[green]Katalog raportu: {config.REPORT_DIR}[/green]"))

        if not config.QUIET_MODE:
            detect_waf_and_propose_safe_mode()

        # --- PHASE 1 ---
        if start_phase <= 1:
            if config.QUIET_MODE or phase1_subdomain.display_phase1_tool_selection_menu(display_banner):
                p1_files, active_urls, all_subdomains = phase1_subdomain.start_phase1_scan()
            else:
                return

        # --- TRANSITION TO PHASE 2 ---
        if start_phase <= 2:
            targets_for_p2 = all_subdomains if all_subdomains else [config.CLEAN_DOMAIN_TARGET]
            if not targets_for_p2: targets_for_p2 = [config.HOSTNAME_TARGET]

            if not config.QUIET_MODE:
                if utils.ask_user_decision("Czy chcesz kontynuować do Fazy 2 (Skanowanie Portów)?", ["y", "n"], "y") == 'n':
                    return # Exit will be handled by the finally block

            if not config.QUIET_MODE:
                critical_subdomains = utils.filter_critical_urls(targets_for_p2)
                if critical_subdomains and len(critical_subdomains) < len(targets_for_p2):
                    urls_to_scan_p2 = ask_scan_scope(targets_for_p2, critical_subdomains, "Fazie 2")
                    if not urls_to_scan_p2: return
                else:
                    urls_to_scan_p2 = targets_for_p2
            else:
                 urls_to_scan_p2 = targets_for_p2

            if config.QUIET_MODE or phase2_port_scanning.display_phase2_tool_selection_menu(display_banner):
                p2_results = phase2_port_scanning.start_port_scan(urls_to_scan_p2, None, None)
            else:
                return
        
        # --- TRANSITION TO PHASE 3 ---
        if start_phase <= 3:
            targets_for_p3 = active_urls if active_urls else [config.ORIGINAL_TARGET]
            if not config.QUIET_MODE:
                if utils.ask_user_decision("Czy chcesz kontynuować do Fazy 3 (Wyszukiwanie Katalogów)?", ["y", "n"], "y") == 'n':
                    return

            if not config.QUIET_MODE:
                critical_urls = utils.filter_critical_urls(targets_for_p3)
                if critical_urls and len(critical_urls) < len(targets_for_p3):
                    urls_to_scan_p3 = ask_scan_scope(targets_for_p3, critical_urls, "Fazie 3")
                    if not urls_to_scan_p3: return
                else:
                    urls_to_scan_p3 = targets_for_p3
            else:
                urls_to_scan_p3 = targets_for_p3
            
            if config.QUIET_MODE or phase3_dirsearch.display_phase3_tool_selection_menu(display_banner):
                p3_results, p3_verified_httpx = phase3_dirsearch.start_dir_search(urls_to_scan_p3, None, None)
            else:
                return

        # --- TRANSITION TO PHASE 4 ---
        if start_phase <= 4:
            urls_from_p3 = p3_results.get("all_dirsearch_results", [])
            targets_for_p4 = sorted(list(set(active_urls + urls_from_p3)))
            if not config.QUIET_MODE:
                if utils.ask_user_decision("Czy chcesz kontynuować do Fazy 4 (Web Crawling)?", ["y", "n"], "y") == 'n':
                    return

            if not config.QUIET_MODE:
                critical_urls_p4 = utils.filter_critical_urls(targets_for_p4)
                if critical_urls_p4 and len(critical_urls_p4) < len(targets_for_p4):
                    urls_to_scan_p4 = ask_scan_scope(targets_for_p4, critical_urls_p4, "Fazie 4")
                    if not urls_to_scan_p4: return
                else:
                    urls_to_scan_p4 = targets_for_p4
            else:
                urls_to_scan_p4 = targets_for_p4
            
            if config.QUIET_MODE or phase4_webcrawling.display_phase4_tool_selection_menu(display_banner):
                p4_results = phase4_webcrawling.start_web_crawl(urls_to_scan_p4, None, None)
            else:
                return

    except KeyboardInterrupt:
        utils.console.print("\n[yellow]Przerwano przez użytkownika.[/yellow]")
    finally:
        if scan_initiated:
            if not no_report:
                generate_html_report(p1_files, p2_results, p3_results, p3_verified_httpx, p4_results)
                report_path = os.path.join(config.REPORT_DIR, "report.html")
                if os.path.exists(report_path) and not config.QUIET_MODE:
                    if utils.ask_user_decision("Otworzyć raport HTML?", ["y","n"], "y") == 'y':
                        open_html_report(report_path)
            cleanup_temp_files()

if __name__ == "__main__":
    typer.run(main)

